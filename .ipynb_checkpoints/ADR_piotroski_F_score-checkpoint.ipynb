{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc51ce1",
   "metadata": {
    "id": "fbc51ce1"
   },
   "source": [
    "### <span style=\"color:red\">NOTE: While this code includes the major parts of the analysis, it is still </span><span style=\"text-decoration:underline;color:red\">work in progress and being finalized</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231fb19c",
   "metadata": {
    "id": "231fb19c"
   },
   "source": [
    "# 1. Identify the list of foreign ADRs and extract it for use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2158437c",
   "metadata": {
    "id": "2158437c"
   },
   "source": [
    "The stock universe used in this research is from **adr.com**, a  website owned by J.P. Morgan that houses information on depositary receipts including ADR stocks. From this data, the list of ADR stocks and their ticker names are identified. The list of ADRs  extracted from **adr.com** is saved at: https://github.com/rexlaboratory/adr-piotroski-f-score/tree/main/adr-universe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78352919",
   "metadata": {
    "id": "78352919"
   },
   "source": [
    "# 2. Retrieve financial data using YahooQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda6ac7",
   "metadata": {},
   "source": [
    "Using the Yahoo Query Python package (primarily), the financial information of the ADR stocks are retrieved from Yahoo Finance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e32df516",
   "metadata": {
    "id": "e32df516"
   },
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yahooquery as yq\n",
    "from yahooquery import Ticker\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent\n",
    "import logging\n",
    "import pandas_datareader\n",
    "from pandas_datareader import data as pdr\n",
    "import jinja2\n",
    "import warnings\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "warnings.filterwarnings(\"ignore\") # Ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb26f2",
   "metadata": {
    "id": "71cb26f2"
   },
   "outputs": [],
   "source": [
    "# Specify the folder containing the ADR list\n",
    "folder_path = './adr-universe'\n",
    "\n",
    "# Retrieve the ADR list data from the files in folder_path; loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Read data from the Excel file into a DataFrame\n",
    "        df_adr = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d06d34",
   "metadata": {
    "id": "42d06d34",
    "outputId": "12934b14-924f-49d3-f3e2-6b3aaf8db5ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2498"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many records\n",
    "len(df_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956046ce",
   "metadata": {
    "id": "956046ce"
   },
   "outputs": [],
   "source": [
    "# Filter to include ADRs only\n",
    "df_adr = df_adr[df_adr['Type'] == 'ADR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e46288",
   "metadata": {
    "id": "80e46288",
    "outputId": "750b0cf2-ac88-43d4-9881-8c41fb6e9dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2177"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many records remain after filtering\n",
    "len(df_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43304eda",
   "metadata": {
    "id": "43304eda",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store ADR ticker names in a list\n",
    "tickers_list = df_adr['Symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4806022",
   "metadata": {
    "id": "b4806022"
   },
   "outputs": [],
   "source": [
    "#Columns to retrieve from Yahoo Finance via Yahoo Query\n",
    "columns_to_extract = [\n",
    "    'asOfDate', 'periodType', 'NetIncome', 'GrossProfit', 'PretaxIncome',\n",
    "    'TotalRevenue', 'LongTermDebt', 'LongTermDebtAndCapitalLeaseObligation',\n",
    "    'TotalAssets', 'CurrentAssets', 'CurrentLiabilities', 'OperatingCashFlow',\n",
    "    'DilutedEPS', 'ShareIssued'\n",
    "]\n",
    "\n",
    "# List of tickers\n",
    "tickers = tickers_list\n",
    "\n",
    "\n",
    "#Define a function to fetch the data\n",
    "def fetch_data(ticker):\n",
    "    try:\n",
    "        # Get income statement data for the current ticker\n",
    "        financial_data = Ticker(ticker).all_financial_data()\n",
    "\n",
    "        # Extract the specified columns (with null values for non-existing columns)\n",
    "        data_for_ticker = {column: financial_data.get(column) for column in columns_to_extract}\n",
    "\n",
    "        # Add 'ticker' as a key to the dictionary\n",
    "        data_for_ticker['ticker'] = ticker\n",
    "\n",
    "        # Convert the dictionary to a DataFrame and return it\n",
    "        return pd.DataFrame(data_for_ticker)\n",
    "    except Exception as e:\n",
    "        # print(f\"Error fetching data for {ticker}: {str(e)}\")\n",
    "\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581ad8e",
   "metadata": {
    "id": "f581ad8e",
    "outputId": "0aaa376a-1e39-4136-9a4a-8973116552fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Data: 100%|███████████████████████████████████████████████████████████████| 2177/2177 [14:22<00:00,  2.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Note: Running this code may take a while to complete. ThreadPool helped gain a slight improvement in run time.\n",
    "\n",
    "# Parallel processing to fetch the financial data\n",
    "with ThreadPoolExecutor() as executor, tqdm(total=len(tickers), desc=\"Fetching Data\") as pbar:\n",
    "    # Fetch data for all tickers concurrently\n",
    "    df_list = list(executor.map(lambda ticker: (pbar.update(1) or fetch_data(ticker)), tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4884c",
   "metadata": {
    "id": "3cc4884c"
   },
   "outputs": [],
   "source": [
    "# Filter out unsuccessful fetches (False values)\n",
    "df_list1 = [df for df in df_list if isinstance(df, pd.DataFrame) and not df.empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecae715",
   "metadata": {
    "id": "8ecae715",
    "outputId": "148efff3-bf9f-495d-f67f-0b433f2c44fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rexeu\\AppData\\Local\\Temp\\ipykernel_14984\\1365732248.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df1 = pd.concat(df_list1, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Combine individual DataFrames into one DataFrame\n",
    "df1 = pd.concat(df_list1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a827a3",
   "metadata": {
    "id": "80a827a3",
    "outputId": "f7b71390-5671-44ff-e93c-af5b83487d35",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asOfDate</th>\n",
       "      <th>periodType</th>\n",
       "      <th>NetIncome</th>\n",
       "      <th>GrossProfit</th>\n",
       "      <th>PretaxIncome</th>\n",
       "      <th>TotalRevenue</th>\n",
       "      <th>LongTermDebt</th>\n",
       "      <th>LongTermDebtAndCapitalLeaseObligation</th>\n",
       "      <th>TotalAssets</th>\n",
       "      <th>CurrentAssets</th>\n",
       "      <th>CurrentLiabilities</th>\n",
       "      <th>OperatingCashFlow</th>\n",
       "      <th>DilutedEPS</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>12M</td>\n",
       "      <td>-2.709347e+09</td>\n",
       "      <td>1.076011e+09</td>\n",
       "      <td>-2.581792e+09</td>\n",
       "      <td>4.829019e+09</td>\n",
       "      <td>3.901053e+09</td>\n",
       "      <td>5.234680e+09</td>\n",
       "      <td>1.937376e+10</td>\n",
       "      <td>6.055607e+09</td>\n",
       "      <td>6.121960e+09</td>\n",
       "      <td>7.142430e+08</td>\n",
       "      <td>-26.8200</td>\n",
       "      <td>VNET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>12M</td>\n",
       "      <td>5.000980e+08</td>\n",
       "      <td>1.438030e+09</td>\n",
       "      <td>6.651740e+08</td>\n",
       "      <td>6.189801e+09</td>\n",
       "      <td>6.481966e+09</td>\n",
       "      <td>9.885772e+09</td>\n",
       "      <td>2.309504e+10</td>\n",
       "      <td>5.324123e+09</td>\n",
       "      <td>5.179995e+09</td>\n",
       "      <td>1.387922e+09</td>\n",
       "      <td>-2.1600</td>\n",
       "      <td>VNET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>12M</td>\n",
       "      <td>-7.759520e+08</td>\n",
       "      <td>1.358256e+09</td>\n",
       "      <td>-6.304550e+08</td>\n",
       "      <td>7.065232e+09</td>\n",
       "      <td>8.909115e+09</td>\n",
       "      <td>1.286204e+10</td>\n",
       "      <td>2.694840e+10</td>\n",
       "      <td>7.052276e+09</td>\n",
       "      <td>6.332085e+09</td>\n",
       "      <td>2.440214e+09</td>\n",
       "      <td>-5.2200</td>\n",
       "      <td>VNET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>12M</td>\n",
       "      <td>2.140000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.150000e+08</td>\n",
       "      <td>3.310000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.950000e+08</td>\n",
       "      <td>8.567000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>TGOPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>12M</td>\n",
       "      <td>7.090000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.090000e+08</td>\n",
       "      <td>8.220000e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TGOPY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    asOfDate periodType     NetIncome   GrossProfit  PretaxIncome  \\\n",
       "0 2020-12-31        12M -2.709347e+09  1.076011e+09 -2.581792e+09   \n",
       "1 2021-12-31        12M  5.000980e+08  1.438030e+09  6.651740e+08   \n",
       "2 2022-12-31        12M -7.759520e+08  1.358256e+09 -6.304550e+08   \n",
       "3 2020-03-31        12M  2.140000e+08           NaN  2.150000e+08   \n",
       "4 2020-09-30        12M  7.090000e+08           NaN  7.090000e+08   \n",
       "\n",
       "   TotalRevenue  LongTermDebt  LongTermDebtAndCapitalLeaseObligation  \\\n",
       "0  4.829019e+09  3.901053e+09                           5.234680e+09   \n",
       "1  6.189801e+09  6.481966e+09                           9.885772e+09   \n",
       "2  7.065232e+09  8.909115e+09                           1.286204e+10   \n",
       "3  3.310000e+08           NaN                           5.950000e+08   \n",
       "4  8.220000e+08           NaN                                    NaN   \n",
       "\n",
       "    TotalAssets  CurrentAssets  CurrentLiabilities  OperatingCashFlow  \\\n",
       "0  1.937376e+10   6.055607e+09        6.121960e+09       7.142430e+08   \n",
       "1  2.309504e+10   5.324123e+09        5.179995e+09       1.387922e+09   \n",
       "2  2.694840e+10   7.052276e+09        6.332085e+09       2.440214e+09   \n",
       "3  8.567000e+09            NaN                 NaN                NaN   \n",
       "4           NaN            NaN                 NaN                NaN   \n",
       "\n",
       "   DilutedEPS ticker  \n",
       "0    -26.8200   VNET  \n",
       "1     -2.1600   VNET  \n",
       "2     -5.2200   VNET  \n",
       "3      0.1105  TGOPY  \n",
       "4         NaN  TGOPY  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few records\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df11663",
   "metadata": {
    "id": "9df11663",
    "outputId": "785b1543-df5e-4630-c05f-0875e37833ba",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique tickers fetched\n",
    "len(df1['ticker'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8862a3f",
   "metadata": {
    "id": "a8862a3f"
   },
   "source": [
    "# 3. Transform data and compute Piotroski F-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baaef31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For improved readability of results, define a function to add a title to a dataframe\n",
    "def with_title(df, title):\n",
    "    return df.style.set_caption(title).set_table_styles([{\n",
    "        'selector': 'caption',\n",
    "        'props': [('text-align', 'center')]\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131d5b6",
   "metadata": {
    "id": "2131d5b6"
   },
   "outputs": [],
   "source": [
    "# For historical reference, write the cleansed ADR data to an Excel file\n",
    "df1.to_excel('./output-files/cleansed_adr_list.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7d2a7",
   "metadata": {
    "id": "eca7d2a7"
   },
   "outputs": [],
   "source": [
    "# Convert 'asOfDate' to datetime type\n",
    "df1['asOfDate'] = pd.to_datetime(df1['asOfDate'])\n",
    "\n",
    "# Create a copy of df1\n",
    "df1_copy = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d98a46",
   "metadata": {
    "id": "a9d98a46"
   },
   "outputs": [],
   "source": [
    "# Remove duplicate records using both 'asOfDate' and 'ticker'\n",
    "df1_copy.drop_duplicates(subset=['asOfDate', 'ticker'], keep='first', inplace=True)\n",
    "\n",
    "# Filter only the tickers with 'asOfDate' values: '2020-12-31', '2021-12-31', '2022-12-31'\n",
    "target_asofdates = ['2020-12-31', '2021-12-31', '2022-12-31']\n",
    "df_filtered1 = df1_copy[df1_copy['asOfDate'].isin(target_asofdates)]\n",
    "\n",
    "# Filter tickers with ALL three 'asOfDate' records: 2020, 2021, 2022. Ensure all three years have record for each ticker.\n",
    "filtered_tickers = df_filtered1.groupby('ticker')['asOfDate'].transform('nunique') == 3\n",
    "df_filtered2 = df_filtered1[filtered_tickers]\n",
    "df_filtered3 = df_filtered2[df_filtered2['asOfDate'].isin(target_asofdates)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe8c71",
   "metadata": {},
   "source": [
    "## 3.1 Computing for the Piotroski F-Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ad24b",
   "metadata": {},
   "source": [
    "From the financial information, the following nine questions are answered using a binary logic. For each ADR stock in a given year, one (1) point is earned if the answer to the corresponding question is ‘yes’. Otherwise, zero (0) point is given.\n",
    "\n",
    "1. Is Net Income positive?\n",
    "2. Is Operating Cash Flow positive?\n",
    "3. Is Return on Assets (Net Income divided by Total Assets) higher this year compared to last year?\n",
    "4. Is Operating Cash Flow greater than Net Income?\n",
    "5. Is Leverage (Long Term Debt And Capital Lease Obligation divided by Total Assets) lower this year compared to last year? Long Term Debt is used as a proxy in case Long Term Debt And Capital Lease Obligation is not available from Yahoo Finance data.\n",
    "6. Is Liquidity (Current Assets divided by Current Liabilities) higher this year compared to last year?\n",
    "7. Is Shares Issued lower this year compared to last year?\n",
    "8. Is Gross Margin (Gross Profit divided by Total Revenue) higher this year compared to last year? Pretax Income is used as a proxy in case Gross Profit is not available from Yahoo Finance data.\n",
    "9. Is Asset Turnover (Total Revenue divided by Total Assets) higher this year compared to last year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "616a17e0",
   "metadata": {
    "id": "616a17e0"
   },
   "outputs": [],
   "source": [
    "# Define a function to calculate Boolean values for each of the Piotroski criteria\n",
    "# Note: IsLeverage2Improved is used as a proxy for IsLeverage1Improved depending on financial statement format from Yahoo Finance\n",
    "# Note: IsGrossMargin2Improved is be used as a proxy for IsGrossMargin1Improved depending on financial statement format from Yahoo Finance\n",
    "def calculate_boolean_values(df):\n",
    "    df['IsNetIncomePositive'] = (df['NetIncome'] > 0).astype(int)\n",
    "    df['IsOperatingCashFlowPositive'] = (df['OperatingCashFlow'] > 0).astype(int)\n",
    "    df['IsROAImproved'] = ((df['NetIncome'] / df['TotalAssets']) > (df.groupby('ticker')['NetIncome'].shift() / df.groupby('ticker')['TotalAssets'].shift())).astype(int)\n",
    "    df['IsCashFlowGreaterThanNetIncome'] = (df['OperatingCashFlow'] > df['NetIncome']).astype(int)\n",
    "    df['IsLeverage1Improved'] = ((df['LongTermDebtAndCapitalLeaseObligation'] / df['TotalAssets']) < (df.groupby('ticker')['LongTermDebtAndCapitalLeaseObligation'].shift() / df.groupby('ticker')['TotalAssets'].shift())).astype(int)\n",
    "    df['IsLeverage2Improved'] = ((df['LongTermDebt'] / df['TotalAssets']) < (df.groupby('ticker')['LongTermDebt'].shift() / df.groupby('ticker')['TotalAssets'].shift())).astype(int)\n",
    "    df['IsLiquidityImproved'] = ((df['CurrentAssets'] / df['CurrentLiabilities']) > (df.groupby('ticker')['CurrentAssets'].shift() / df.groupby('ticker')['CurrentLiabilities'].shift())).astype(int)\n",
    "    df['IsShareIssuedReduced'] = ((df['ShareIssued']) < (df.groupby('ticker')['ShareIssued'].shift())).astype(int)\n",
    "    df['IsGrossMargin1Improved'] = ((df['GrossProfit'] / df['TotalRevenue']) > (df.groupby('ticker')['GrossProfit'].shift() / df.groupby('ticker')['TotalRevenue'].shift())).astype(int)\n",
    "    df['IsGrossMargin2Improved'] = ((df['PretaxIncome'] / df['TotalRevenue']) > (df.groupby('ticker')['PretaxIncome'].shift() / df.groupby('ticker')['TotalRevenue'].shift())).astype(int)\n",
    "    df['IsAssetTurnoverImproved'] = ((df['TotalRevenue'] / df['TotalAssets']) > (df.groupby('ticker')['TotalRevenue'].shift() / df.groupby('ticker')['TotalAssets'].shift())).astype(int)\n",
    "\n",
    "    # Add Fscore column\n",
    "    df['Fscore'] = (\n",
    "        df['IsNetIncomePositive'] +\n",
    "        df['IsOperatingCashFlowPositive'] +\n",
    "        df['IsROAImproved'] +\n",
    "        df['IsCashFlowGreaterThanNetIncome'] +\n",
    "        df[['IsLeverage1Improved', 'IsLeverage2Improved']].max(axis=1) + # Get only the maximum between the two; IsLeverage2Improved is used as a proxy for IsLeverage1Improved\n",
    "        df['IsLiquidityImproved'] +\n",
    "        df['IsShareIssuedReduced'] +\n",
    "        df[['IsGrossMargin1Improved', 'IsGrossMargin2Improved']].max(axis=1) + # Get only the maximum between the two; IsGrossMargin2Improved can be used as a proxy for IsGrossMargin1Improved\n",
    "        df['IsAssetTurnoverImproved']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63822843",
   "metadata": {
    "id": "63822843"
   },
   "outputs": [],
   "source": [
    "# Calculate the Piotroski criteria value using the function defined earlier\n",
    "calculate_boolean_values(df_filtered3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a68974",
   "metadata": {
    "id": "a3a68974"
   },
   "outputs": [],
   "source": [
    "# Create two new dataframes for 2021 and 2022 summaries\n",
    "df_2021 = df_filtered3[df_filtered3['asOfDate'].dt.year == 2021].copy()\n",
    "df_2022 = df_filtered3[df_filtered3['asOfDate'].dt.year == 2022].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84e2e4",
   "metadata": {
    "id": "1a84e2e4",
    "outputId": "bd935b57-a01a-40f4-8e09-7315e52f6abc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique tickers in 2021 data\n",
    "len(df_2021['ticker'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3906be",
   "metadata": {
    "id": "4f3906be",
    "outputId": "27878b87-772c-4bf8-bed7-87aaaf152832"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique tickers in 2022 data\n",
    "len(df_2022['ticker'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9edfd3",
   "metadata": {
    "id": "ae9edfd3"
   },
   "outputs": [],
   "source": [
    "# For historical reference, save the Fscore data to Excel files\n",
    "fscore_file_path = './output-files/adr_piotroskFscores_2021_2022.xlsx'\n",
    "df_filtered3.to_excel(fscore_file_path, index=False)\n",
    "\n",
    "# For historical reference, save the 2021 Fscore data to Excel files\n",
    "fscore_2021_file_path = './output-files/adr_piotroskFscores_2021.xlsx'\n",
    "df_2021.to_excel(fscore_2021_file_path, index=False)\n",
    "\n",
    "# For historical reference, save the 2022 Fscore data to Excel files\n",
    "fscore_2022_file_path = './output-files/adr_piotroskiFscores_2022.xlsx'\n",
    "df_2022.to_excel(fscore_2022_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52c023",
   "metadata": {
    "id": "dd52c023"
   },
   "outputs": [],
   "source": [
    "# Define a variable 'basket_df' as the stock basket\n",
    "basket_df = df_2021\n",
    "\n",
    "# Define the start dates and end dates range for downloading the ADR stock price (close price)\n",
    "start_date_2022 = '2022-01-03'\n",
    "start_date_2022_1 = '2022-01-04'\n",
    "\n",
    "end_date_2022 = '2022-12-30'\n",
    "end_date_2022_1 = '2022-12-31'\n",
    "\n",
    "start_date_2023 = '2023-01-03'\n",
    "start_date_2023_1 = '2023-01-04'\n",
    "\n",
    "end_date_2023 = '2023-12-29'\n",
    "end_date_2023_1 = '2023-12-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a5503",
   "metadata": {
    "id": "f36a5503",
    "outputId": "c6ad076d-03ef-4f1e-8ece-fcaaf85d42f9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  742 of 742 completed\n",
      "\n",
      "50 Failed downloads:\n",
      "- HAGHY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- AKRBY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- JDHIY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- GEDRY: No data found, symbol may be delisted\n",
      "- PSPSY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- HXXPY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- TCBP: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- DRPRY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- THGHY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- SVRE: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- NDWTY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- BKFKY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- NIABY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- AKBDY: No data found, symbol may be delisted\n",
      "- CIG/C: No data found for this date range, symbol may be delisted\n",
      "- NPPHY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- CDLR: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- NRGIY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- MLTTY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- CTNGY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- BTTAY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- TCGGY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- ABHBY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- CHLSY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- CCPEL: No data found, symbol may be delisted\n",
      "- JSLGY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- AKO/B: No data found for this date range, symbol may be delisted\n",
      "- SIGCY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- CGNWY: No data found, symbol may be delisted\n",
      "- EXTO: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- CFACY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- TKKYY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- TGASY: No data found, symbol may be delisted\n",
      "- CNHHY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- BTSNY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- UDIRY: No data found, symbol may be delisted\n",
      "- KZHXY: No data found, symbol may be delisted\n",
      "- TTVSY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- ASBRY: No data found for this date range, symbol may be delisted\n",
      "- VWAPY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- VLVCY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- ZHHJY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- RICFY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- HLN: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- MPZAY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- FLDAY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- WILWY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- GPCR: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- HCXLY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "- GNZUY: Data doesn't exist for startDate = 1641186000, endDate = 1641272400\n",
      "[*********************100%***********************]  742 of 742 completed\n",
      "\n",
      "32 Failed downloads:\n",
      "- AKRBY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- GEDRY: No data found, symbol may be delisted\n",
      "- PSPSY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- NDWTY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- BKFKY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- CIG/C: No data found for this date range, symbol may be delisted\n",
      "- AKBDY: No data found, symbol may be delisted\n",
      "- NPPHY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- CDLR: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- NRGIY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- MLTTY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- ABHBY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- CCPEL: No data found, symbol may be delisted\n",
      "- JSLGY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- AKO/B: No data found for this date range, symbol may be delisted\n",
      "- CGNWY: No data found, symbol may be delisted\n",
      "- EXTO: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- CFACY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- TGASY: No data found, symbol may be delisted\n",
      "- CNHHY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- BTSNY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- UDIRY: No data found, symbol may be delisted\n",
      "- KZHXY: No data found, symbol may be delisted\n",
      "- TTVSY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- ASBRY: No data found for this date range, symbol may be delisted\n",
      "- VWAPY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- ZHHJY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- RICFY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- FLDAY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- WILWY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- GPCR: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "- GNZUY: Data doesn't exist for startDate = 1672376400, endDate = 1672462800\n",
      "[*********************100%***********************]  742 of 742 completed\n",
      "\n",
      "32 Failed downloads:\n",
      "- AKRBY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- GEDRY: No data found, symbol may be delisted\n",
      "- PSPSY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- NDWTY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- BKFKY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- AKBDY: No data found, symbol may be delisted\n",
      "- CIG/C: No data found for this date range, symbol may be delisted\n",
      "- NPPHY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- CDLR: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- NRGIY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- MLTTY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- ABHBY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- CCPEL: No data found, symbol may be delisted\n",
      "- JSLGY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- AKO/B: No data found for this date range, symbol may be delisted\n",
      "- CGNWY: No data found, symbol may be delisted\n",
      "- EXTO: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- CFACY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- TGASY: No data found, symbol may be delisted\n",
      "- CNHHY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- BTSNY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- UDIRY: No data found, symbol may be delisted\n",
      "- KZHXY: No data found, symbol may be delisted\n",
      "- TTVSY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- ASBRY: No data found for this date range, symbol may be delisted\n",
      "- VWAPY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- ZHHJY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- RICFY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- FLDAY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- WILWY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- GPCR: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n",
      "- GNZUY: Data doesn't exist for startDate = 1672722000, endDate = 1672808400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  742 of 742 completed\n",
      "\n",
      "16 Failed downloads:\n",
      "- GEDRY: No data found, symbol may be delisted\n",
      "- DSGUY: No data found for this date range, symbol may be delisted\n",
      "- AKBDY: No data found, symbol may be delisted\n",
      "- CIG/C: No data found for this date range, symbol may be delisted\n",
      "- CCPEL: No data found, symbol may be delisted\n",
      "- AKO/B: No data found for this date range, symbol may be delisted\n",
      "- CGNWY: No data found, symbol may be delisted\n",
      "- TGASY: No data found, symbol may be delisted\n",
      "- UDIRY: No data found, symbol may be delisted\n",
      "- STWRY: No data found for this date range, symbol may be delisted\n",
      "- KZHXY: No data found, symbol may be delisted\n",
      "- ASBRY: No data found for this date range, symbol may be delisted\n",
      "- GRVY: No data found for this date range, symbol may be delisted\n",
      "- MOHCY: No data found for this date range, symbol may be delisted\n",
      "- PANDY: No data found for this date range, symbol may be delisted\n",
      "- RICFY: No data found for this date range, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "# Note: Fetching the daily stock price data for 2-year range for hundreds of stocks may take a while.\n",
    "\n",
    "# Fetch adjusted close prices at the defined date range\n",
    "start_prices_2022 = yf.download(basket_df['ticker'].tolist(), start = start_date_2022, end = start_date_2022_1)['Close']\n",
    "end_prices_2022 = yf.download(basket_df['ticker'].tolist(), start = end_date_2022, end = end_date_2022_1)['Close']\n",
    "start_prices_2023 = yf.download(basket_df['ticker'].tolist(), start = start_date_2023, end = start_date_2023_1)['Close']\n",
    "end_prices_2023 = yf.download(basket_df['ticker'].tolist(), start = end_date_2023, end = end_date_2023_1)['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f193e7",
   "metadata": {},
   "source": [
    "Some of the stocks (e.g., delisted stocks in a particular year) do not have price data. For example, in 2022 there are 50 stocks (out of 742) without price data, while we have complete price data for 692 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72730c4",
   "metadata": {
    "id": "c72730c4"
   },
   "outputs": [],
   "source": [
    "# For historical reference, save the successfully retrieved ADR stock price data to Excel files\n",
    "start_prices_2022.to_excel('./output-files/start_prices_2022.xlsx', index=False)\n",
    "end_prices_2022.to_excel('./output-files/end_prices_2022.xlsx', index=False)\n",
    "start_prices_2023.to_excel('./output-files/start_prices_2023.xlsx', index=False)\n",
    "end_prices_2023.to_excel('./output-files/end_prices_2023.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae82731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the Fscore Excel data processed earlier\n",
    "\n",
    "fscore_file_path = './output-files/adr_piotroskFscores_2021_2022.xlsx'\n",
    "fscore_2021_file_path = './output-files/adr_piotroskFscores_2021.xlsx'\n",
    "fscore_2022_file_path = './output-files/adr_piotroskiFscores_2022.xlsx'\n",
    "adr_universe_file_path = './adr-universe/dr_universe.xlsx'\n",
    "\n",
    "df_filtered3 = pd.read_excel(fscore_file_path)\n",
    "df_2021 = pd.read_excel(fscore_2021_file_path)\n",
    "df_2022 = pd.read_excel(fscore_2022_file_path)\n",
    "df_adr_ref = pd.read_excel(adr_universe_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d378a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the stock price data processed earlier\n",
    "start_prices_2022 = pd.read_excel('./output-files/start_prices_2022.xlsx')\n",
    "end_prices_2022 = pd.read_excel('./output-files/end_prices_2022.xlsx')\n",
    "start_prices_2023 = pd.read_excel('./output-files/start_prices_2023.xlsx')\n",
    "end_prices_2023 = pd.read_excel('./output-files/end_prices_2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5157ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Fscore and Stock Price data tables with df_adr_ref to lookup the Region and Country\n",
    "\n",
    "df_filtered3 = pd.merge(df_filtered3, df_adr_ref[['Symbol', 'Region', 'Country', 'Level']], left_on='ticker', right_on='Symbol', how='left')\n",
    "df_filtered3 = df_filtered3.drop('Symbol', axis=1)\n",
    "\n",
    "df_2021 = pd.merge(df_2021, df_adr_ref[['Symbol', 'Region', 'Country', 'Level']], left_on='ticker', right_on='Symbol', how='left')\n",
    "df_2021 = df_2021.drop('Symbol', axis=1)\n",
    "\n",
    "df_2022 = pd.merge(df_2022, df_adr_ref[['Symbol', 'Region', 'Country', 'Level']], left_on='ticker', right_on='Symbol', how='left')\n",
    "df_2022 = df_2022.drop('Symbol', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee2bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve stock price data processed earlier\n",
    "end_prices_2022_a = pd.DataFrame(end_prices_2022.iloc[0])\n",
    "end_prices_2023_a = pd.DataFrame(end_prices_2023.iloc[0])\n",
    "start_prices_2022_a = pd.DataFrame(start_prices_2022.iloc[0])\n",
    "start_prices_2023_a = pd.DataFrame(start_prices_2023.iloc[0])\n",
    "\n",
    "# Merge start and end prices for each year for computation of returns\n",
    "merged_2022 = pd.merge(start_prices_2022_a, end_prices_2022_a, left_index=True, right_index=True, how='inner')\n",
    "merged_2023 = pd.merge(start_prices_2023_a, end_prices_2023_a, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Compute percentage returns\n",
    "merged_2022['returns_2022'] = (merged_2022['0_y'] / merged_2022['0_x']) - 1\n",
    "merged_2023['returns_2023'] = (merged_2023['0_y'] / merged_2023['0_x']) - 1\n",
    "\n",
    "# Rename columns\n",
    "merged_2022.rename(columns={'0_x': 'start_price', '0_y': 'end_price'}, inplace=True)\n",
    "merged_2023.rename(columns={'0_x': 'start_price', '0_y': 'end_price'}, inplace=True)\n",
    "\n",
    "# Remove the 'ticker' as index and add as a normal column instead\n",
    "merged_2022.reset_index(inplace=True)\n",
    "merged_2023.reset_index(inplace=True)\n",
    "merged_2022.rename(columns={'index': 'ticker'}, inplace=True)\n",
    "merged_2023.rename(columns={'index': 'ticker'}, inplace=True)\n",
    "\n",
    "# Get Fscore, Country and Region data thru joining\n",
    "merged_2022 = pd.merge(merged_2022, df_2021[['ticker', 'Fscore', 'Region', 'Country']], left_on='ticker', right_on='ticker', how='left')\n",
    "merged_2023 = pd.merge(merged_2023, df_2022[['ticker', 'Fscore', 'Region', 'Country']], left_on='ticker', right_on='ticker', how='left')\n",
    "\n",
    "# Create a merged dataframe with combined 2022 and 2023 data\n",
    "merged_2022_2023 = pd.merge(merged_2022, merged_2023, on='ticker', how='inner')\n",
    "merged_2022_2023 = merged_2022_2023.dropna() # drop records with NA values\n",
    "\n",
    "del merged_2022_2023['Country_y'] # delete column, not needed\n",
    "del merged_2022_2023['Region_y'] # delete column, not needed\n",
    "\n",
    "merged_2022_2023.rename(columns={'start_price_x': 'start_price_2022',\n",
    "                                 'end_price_x': 'end_price_2022',\n",
    "                                 'Fscore_x': 'Fscore_2022',\n",
    "                                 'Region_x': 'Region',\n",
    "                                 'Country_x': 'Country',\n",
    "                                 'start_price_y': 'start_price_2023',\n",
    "                                 'end_price_y': 'end_price_2023',\n",
    "                                 'Fscore_y': 'Fscore_2023',\n",
    "                                },\n",
    "                        inplace=True) # rename columns\n",
    "\n",
    "# Add Fscore_momentum column\n",
    "merged_2022_2023['Fscore_momentum'] = merged_2022_2023['Fscore_2023'] - merged_2022_2023['Fscore_2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b78679a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f05c5 caption {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f05c5\">\n",
       "  <caption>Table 1. First Few Records of Returns Data</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f05c5_level0_col0\" class=\"col_heading level0 col0\" >ticker</th>\n",
       "      <th id=\"T_f05c5_level0_col1\" class=\"col_heading level0 col1\" >start_price_2022</th>\n",
       "      <th id=\"T_f05c5_level0_col2\" class=\"col_heading level0 col2\" >end_price_2022</th>\n",
       "      <th id=\"T_f05c5_level0_col3\" class=\"col_heading level0 col3\" >returns_2022</th>\n",
       "      <th id=\"T_f05c5_level0_col4\" class=\"col_heading level0 col4\" >Fscore_2022</th>\n",
       "      <th id=\"T_f05c5_level0_col5\" class=\"col_heading level0 col5\" >Region</th>\n",
       "      <th id=\"T_f05c5_level0_col6\" class=\"col_heading level0 col6\" >Country</th>\n",
       "      <th id=\"T_f05c5_level0_col7\" class=\"col_heading level0 col7\" >start_price_2023</th>\n",
       "      <th id=\"T_f05c5_level0_col8\" class=\"col_heading level0 col8\" >end_price_2023</th>\n",
       "      <th id=\"T_f05c5_level0_col9\" class=\"col_heading level0 col9\" >returns_2023</th>\n",
       "      <th id=\"T_f05c5_level0_col10\" class=\"col_heading level0 col10\" >Fscore_2023</th>\n",
       "      <th id=\"T_f05c5_level0_col11\" class=\"col_heading level0 col11\" >Fscore_momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f05c5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f05c5_row0_col0\" class=\"data row0 col0\" >AAALY</td>\n",
       "      <td id=\"T_f05c5_row0_col1\" class=\"data row0 col1\" >33.450001</td>\n",
       "      <td id=\"T_f05c5_row0_col2\" class=\"data row0 col2\" >34.650002</td>\n",
       "      <td id=\"T_f05c5_row0_col3\" class=\"data row0 col3\" >0.035874</td>\n",
       "      <td id=\"T_f05c5_row0_col4\" class=\"data row0 col4\" >7</td>\n",
       "      <td id=\"T_f05c5_row0_col5\" class=\"data row0 col5\" >Dev. Europe</td>\n",
       "      <td id=\"T_f05c5_row0_col6\" class=\"data row0 col6\" >Germany</td>\n",
       "      <td id=\"T_f05c5_row0_col7\" class=\"data row0 col7\" >34.650002</td>\n",
       "      <td id=\"T_f05c5_row0_col8\" class=\"data row0 col8\" >34.650002</td>\n",
       "      <td id=\"T_f05c5_row0_col9\" class=\"data row0 col9\" >0.000000</td>\n",
       "      <td id=\"T_f05c5_row0_col10\" class=\"data row0 col10\" >5</td>\n",
       "      <td id=\"T_f05c5_row0_col11\" class=\"data row0 col11\" >-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f05c5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f05c5_row1_col0\" class=\"data row1 col0\" >AACAY</td>\n",
       "      <td id=\"T_f05c5_row1_col1\" class=\"data row1 col1\" >3.900000</td>\n",
       "      <td id=\"T_f05c5_row1_col2\" class=\"data row1 col2\" >2.200000</td>\n",
       "      <td id=\"T_f05c5_row1_col3\" class=\"data row1 col3\" >-0.435897</td>\n",
       "      <td id=\"T_f05c5_row1_col4\" class=\"data row1 col4\" >5</td>\n",
       "      <td id=\"T_f05c5_row1_col5\" class=\"data row1 col5\" >Emrg. Asia</td>\n",
       "      <td id=\"T_f05c5_row1_col6\" class=\"data row1 col6\" >China</td>\n",
       "      <td id=\"T_f05c5_row1_col7\" class=\"data row1 col7\" >2.240000</td>\n",
       "      <td id=\"T_f05c5_row1_col8\" class=\"data row1 col8\" >2.890000</td>\n",
       "      <td id=\"T_f05c5_row1_col9\" class=\"data row1 col9\" >0.290179</td>\n",
       "      <td id=\"T_f05c5_row1_col10\" class=\"data row1 col10\" >2</td>\n",
       "      <td id=\"T_f05c5_row1_col11\" class=\"data row1 col11\" >-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f05c5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f05c5_row2_col0\" class=\"data row2 col0\" >AAGIY</td>\n",
       "      <td id=\"T_f05c5_row2_col1\" class=\"data row2 col1\" >40.650002</td>\n",
       "      <td id=\"T_f05c5_row2_col2\" class=\"data row2 col2\" >44.430000</td>\n",
       "      <td id=\"T_f05c5_row2_col3\" class=\"data row2 col3\" >0.092989</td>\n",
       "      <td id=\"T_f05c5_row2_col4\" class=\"data row2 col4\" >4</td>\n",
       "      <td id=\"T_f05c5_row2_col5\" class=\"data row2 col5\" >Dev. Asia</td>\n",
       "      <td id=\"T_f05c5_row2_col6\" class=\"data row2 col6\" >Hong Kong</td>\n",
       "      <td id=\"T_f05c5_row2_col7\" class=\"data row2 col7\" >45.799999</td>\n",
       "      <td id=\"T_f05c5_row2_col8\" class=\"data row2 col8\" >34.669998</td>\n",
       "      <td id=\"T_f05c5_row2_col9\" class=\"data row2 col9\" >-0.243013</td>\n",
       "      <td id=\"T_f05c5_row2_col10\" class=\"data row2 col10\" >4</td>\n",
       "      <td id=\"T_f05c5_row2_col11\" class=\"data row2 col11\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f05c5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f05c5_row3_col0\" class=\"data row3 col0\" >AAVMY</td>\n",
       "      <td id=\"T_f05c5_row3_col1\" class=\"data row3 col1\" >14.830000</td>\n",
       "      <td id=\"T_f05c5_row3_col2\" class=\"data row3 col2\" >13.820000</td>\n",
       "      <td id=\"T_f05c5_row3_col3\" class=\"data row3 col3\" >-0.068105</td>\n",
       "      <td id=\"T_f05c5_row3_col4\" class=\"data row3 col4\" >6</td>\n",
       "      <td id=\"T_f05c5_row3_col5\" class=\"data row3 col5\" >Dev. Europe</td>\n",
       "      <td id=\"T_f05c5_row3_col6\" class=\"data row3 col6\" >Netherlands</td>\n",
       "      <td id=\"T_f05c5_row3_col7\" class=\"data row3 col7\" >14.570000</td>\n",
       "      <td id=\"T_f05c5_row3_col8\" class=\"data row3 col8\" >14.980000</td>\n",
       "      <td id=\"T_f05c5_row3_col9\" class=\"data row3 col9\" >0.028140</td>\n",
       "      <td id=\"T_f05c5_row3_col10\" class=\"data row3 col10\" >6</td>\n",
       "      <td id=\"T_f05c5_row3_col11\" class=\"data row3 col11\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f05c5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f05c5_row4_col0\" class=\"data row4 col0\" >ABDBY</td>\n",
       "      <td id=\"T_f05c5_row4_col1\" class=\"data row4 col1\" >3.550000</td>\n",
       "      <td id=\"T_f05c5_row4_col2\" class=\"data row4 col2\" >4.040000</td>\n",
       "      <td id=\"T_f05c5_row4_col3\" class=\"data row4 col3\" >0.138028</td>\n",
       "      <td id=\"T_f05c5_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_f05c5_row4_col5\" class=\"data row4 col5\" >Dev. Europe</td>\n",
       "      <td id=\"T_f05c5_row4_col6\" class=\"data row4 col6\" >Denmark</td>\n",
       "      <td id=\"T_f05c5_row4_col7\" class=\"data row4 col7\" >4.040000</td>\n",
       "      <td id=\"T_f05c5_row4_col8\" class=\"data row4 col8\" >4.040000</td>\n",
       "      <td id=\"T_f05c5_row4_col9\" class=\"data row4 col9\" >0.000000</td>\n",
       "      <td id=\"T_f05c5_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_f05c5_row4_col11\" class=\"data row4 col11\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b5e10543a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For historical reference, save the compiled data to an Excel file\n",
    "merged_2022_2023.to_excel('./output-files/compiled_stock_level_info.xlsx', index=False)\n",
    "\n",
    "# View the returns data - first few records\n",
    "with_title(merged_2022_2023.head(), \"Table 1. First Few Records of Returns Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1ddd9",
   "metadata": {},
   "source": [
    "For more concise grouping in our summary later, we add Market Classification column derived from the data in Region column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfcdb07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"Market Classification\" column\n",
    "merged_2022_2023['Market Classification'] = merged_2022_2023['Region'].replace({'Dev. Europe': 'Non-U.S. Developed Markets',\n",
    "                                     'Dev. Asia': 'Non-U.S. Developed Markets',\n",
    "                                     'Emrg. Asia': 'Non-U.S. Emerging Markets',\n",
    "                                     'Emrg. Europe': 'Non-U.S. Emerging Markets',\n",
    "                                     'Latin America': 'Non-U.S. Emerging Markets',\n",
    "                                     'Middle East / Africa': 'Non-U.S. Emerging Markets'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1e61f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c40d5 caption {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c40d5\">\n",
       "  <caption>Table 2. Number of Countries and ADR Stocks by Market Classification</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c40d5_level0_col0\" class=\"col_heading level0 col0\" >Count of ADR Stocks</th>\n",
       "      <th id=\"T_c40d5_level0_col1\" class=\"col_heading level0 col1\" >Count of Countries</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Market Classification</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c40d5_level0_row0\" class=\"row_heading level0 row0\" >Non-U.S. Developed Markets</th>\n",
       "      <td id=\"T_c40d5_row0_col0\" class=\"data row0 col0\" >429</td>\n",
       "      <td id=\"T_c40d5_row0_col1\" class=\"data row0 col1\" >24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40d5_level0_row1\" class=\"row_heading level0 row1\" >Non-U.S. Emerging Markets</th>\n",
       "      <td id=\"T_c40d5_row1_col0\" class=\"data row1 col0\" >258</td>\n",
       "      <td id=\"T_c40d5_row1_col1\" class=\"data row1 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40d5_level0_row2\" class=\"row_heading level0 row2\" >Total</th>\n",
       "      <td id=\"T_c40d5_row2_col0\" class=\"data row2 col0\" >687</td>\n",
       "      <td id=\"T_c40d5_row2_col1\" class=\"data row2 col1\" >49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e4abad0b80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table = pd.pivot_table(merged_2022_2023, values='Country', index='Market Classification', aggfunc={'Country': ['count', 'nunique']}, fill_value=0)\n",
    "summary_table.columns = ['Count of ADR Stocks', 'Count of Countries']\n",
    "#summary_table['Total'] = summary_table.sum(axis=1)\n",
    "summary_table.loc['Total'] = summary_table.sum()\n",
    "with_title(summary_table, 'Table 2. Number of Countries and ADR Stocks by Market Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f0be7",
   "metadata": {
    "id": "417f0be7"
   },
   "source": [
    "# 4. Measure by Market Group. Compute returns and compare by Region: High-F-score stocks VS Low-F-score stocks VS ADR Stock Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8e09a",
   "metadata": {},
   "source": [
    "## 4.1  Set up the ADR stock index and compute for the returns\n",
    "The ADR Stock Index is created using equal-weighted returns of all the ADR stocks in a particular 'market classification'. This is used as a baseline when comparing the performance of high-F-score and low-F-score stocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a59ea0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Declare what level of information should appear in the rows of the summary tables.\n",
    "For example, use pivot_row='Region' if summary by region is needed,\n",
    "use pivot_row='Level' if summary by ADR level is needed, and so on.\n",
    "'''\n",
    "pivot_row = 'Market Classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca51359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate equal-weighted returns (Index)\n",
    "def equal_weighted_returns(df):\n",
    "    return df['returns'].mean().mean()\n",
    "\n",
    "# Define a function to calculate fscore-momentum-weighted returns\n",
    "def fscore_weighted_returns(df, weight_column):\n",
    "    total_weight = df[weight_column].sum()\n",
    "    weighted_returns = (df['returns'] * df[weight_column] / total_weight).sum()\n",
    "    return weighted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c437eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate other metrics such as precision metrics\n",
    "\n",
    "def calculate_accuracy(df, pivot_row):\n",
    "    # Create a dictionary to store the results\n",
    "    summary_dict = {pivot_row: [], 'Expected Winner': [], 'Actual Winner': [], 'Expected Loser': [], 'Actual Loser': [], 'HF Precision': [], 'LF Precision': [], 'Overall Precision': []}\n",
    "    \n",
    "    # Calculate and add metrics for each pivot_row\n",
    "    for value in df[pivot_row].unique():\n",
    "        value_df = df[df[pivot_row] == value]\n",
    "\n",
    "        # Expected Winner (EW)\n",
    "        ew = len(value_df[(value_df['Fscore'] > 6)])\n",
    "\n",
    "        # Actual Winner (AW)\n",
    "        aw = len(value_df[(value_df['Fscore'] > 6) & (value_df['returns'] > equal_weighted_returns(value_df))])\n",
    "\n",
    "        # Expected Loser (EL)\n",
    "        el = len(value_df[(value_df['Fscore'] < 4)])\n",
    "\n",
    "        # Actual Loser (AL)\n",
    "        al = len(value_df[(value_df['Fscore'] < 4) & (value_df['returns'] < equal_weighted_returns(value_df))])\n",
    "\n",
    "        # Precision\n",
    "        hf_precision = aw / ew\n",
    "        lf_precision = al / el\n",
    "        overall_precision = (aw + al) / (ew + el)\n",
    "\n",
    "        # Add data to the summary dictionary\n",
    "        summary_dict[pivot_row].append(value)\n",
    "        summary_dict['Expected Winner'].append(ew)\n",
    "        summary_dict['Actual Winner'].append(aw)\n",
    "        summary_dict['Expected Loser'].append(el)\n",
    "        summary_dict['Actual Loser'].append(al)\n",
    "        summary_dict['HF Precision'].append(hf_precision)\n",
    "        summary_dict['LF Precision'].append(lf_precision)\n",
    "        summary_dict['Overall Precision'].append(overall_precision)\n",
    "\n",
    "    # Convert lists to Pandas Series before calculating sums\n",
    "    expected_winner_series = pd.Series(summary_dict['Expected Winner'])\n",
    "    actual_winner_series = pd.Series(summary_dict['Actual Winner'])\n",
    "    expected_loser_series = pd.Series(summary_dict['Expected Loser'])\n",
    "    actual_loser_series = pd.Series(summary_dict['Actual Loser'])\n",
    "\n",
    "    # Calculate overall metrics for the entire dataset\n",
    "    overall_ew = expected_winner_series.sum()\n",
    "    overall_aw = actual_winner_series.sum()\n",
    "    overall_el = expected_loser_series.sum()\n",
    "    overall_al = actual_loser_series.sum()\n",
    "    overall_hf_precision = overall_aw / overall_ew\n",
    "    overall_lf_precision = overall_al / overall_el\n",
    "    overall_overall_precision = (overall_aw + overall_al) / (overall_ew + overall_el)\n",
    "\n",
    "    # Add 'Overall' row to the summary dictionary\n",
    "    summary_dict[pivot_row].append('Overall')\n",
    "    summary_dict['Expected Winner'].append(overall_ew)\n",
    "    summary_dict['Actual Winner'].append(overall_aw)\n",
    "    summary_dict['Expected Loser'].append(overall_el)\n",
    "    summary_dict['Actual Loser'].append(overall_al)\n",
    "    summary_dict['HF Precision'].append(overall_hf_precision)\n",
    "    summary_dict['LF Precision'].append(overall_lf_precision)\n",
    "    summary_dict['Overall Precision'].append(overall_overall_precision)\n",
    "\n",
    "    # Create a DataFrame from the summary dictionary\n",
    "    summary = pd.DataFrame(summary_dict)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfdc4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 2022 Returns by Market Classification\n",
    "pivot_row = 'Market Classification'\n",
    "\n",
    "# Save 2022 data as 'df'\n",
    "columns_selected = ['ticker', 'returns_2022','Fscore_2022', 'Market Classification']\n",
    "df = merged_2022_2023[columns_selected]\n",
    "df.rename(columns={'returns_2022': 'returns',\n",
    "                   'Fscore_2022': 'Fscore'\n",
    "                  }, inplace=True) # rename column\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "summary_dict = {pivot_row: [], 'Index_Returns': [], 'Low_Fscore_Returns': [], 'Medium_Fscore_Returns': [], 'High_Fscore_Returns': []}\n",
    "\n",
    "# Calculate and add returns for Fscore categories and by pivot_row\n",
    "for value in df[pivot_row].unique():\n",
    "    value_df = df[df[pivot_row] == value]\n",
    "    \n",
    "    # Equal-weighted returns for the region\n",
    "    index_returns = equal_weighted_returns(value_df)\n",
    "    \n",
    "    # Equal-weighted returns for Fscore categories\n",
    "    fscore_0_3_returns = equal_weighted_returns(value_df[(value_df['Fscore'] >= 0) & (value_df['Fscore'] <= 3)])\n",
    "    fscore_4_6_returns = equal_weighted_returns(value_df[(value_df['Fscore'] >= 4) & (value_df['Fscore'] <= 6)])\n",
    "    fscore_7_9_returns = equal_weighted_returns(value_df[(value_df['Fscore'] >= 7) & (value_df['Fscore'] <= 9)])\n",
    " \n",
    "    # Add data to the summary dictionary\n",
    "    summary_dict[pivot_row].append(value)\n",
    "    summary_dict['Index_Returns'].append(index_returns)\n",
    "    summary_dict['Low_Fscore_Returns'].append(fscore_0_3_returns)\n",
    "    summary_dict['Medium_Fscore_Returns'].append(fscore_4_6_returns)\n",
    "    summary_dict['High_Fscore_Returns'].append(fscore_7_9_returns)\n",
    "    \n",
    "# Calculate overall returns for the entire dataset (without considering region) for each column\n",
    "overall_returns_index = equal_weighted_returns(df)\n",
    "\n",
    "# Weighted returns for all stocks in the dataset (without considering region)\n",
    "overall_returns_low_fscore = equal_weighted_returns(df[(df['Fscore'] >= 0) & (df['Fscore'] <= 3)])\n",
    "overall_returns_medium_fscore = equal_weighted_returns(df[(df['Fscore'] >= 4) & (df['Fscore'] <= 6)])\n",
    "overall_returns_high_fscore = equal_weighted_returns(df[df['Fscore'] >= 7])\n",
    "\n",
    "# Add data to the summary dictionary for overall returns\n",
    "summary_dict[pivot_row].append('Overall')\n",
    "summary_dict['Index_Returns'].append(overall_returns_index)\n",
    "summary_dict['Low_Fscore_Returns'].append(overall_returns_low_fscore)\n",
    "summary_dict['Medium_Fscore_Returns'].append(overall_returns_medium_fscore)\n",
    "summary_dict['High_Fscore_Returns'].append(overall_returns_high_fscore)\n",
    "    \n",
    "# Create a DataFrame from the summary dictionary\n",
    "summary_df1 = pd.DataFrame(summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "772dce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the other metrics for 2022 by Region: accuracy, specificity, sensitivity, and balanced accuracy\n",
    "summary_df1_metrics = calculate_accuracy(df, pivot_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78f30129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 2023 Returns by Region\n",
    "\n",
    "# Save 2023 data as 'df'\n",
    "columns_selected = ['ticker', 'returns_2023','Fscore_2023', 'Market Classification', 'Fscore_momentum']\n",
    "df = merged_2022_2023[columns_selected]\n",
    "df.rename(columns={'returns_2023': 'returns',\n",
    "                   'Fscore_2023': 'Fscore'\n",
    "                  }, inplace=True) # rename column\n",
    "\n",
    "# Define weights for each Fscore_momentum\n",
    "weights = {0: 9, 1: 9, 2: 10, 3: 10, 4: 11, 5: 11, 6: 12, 7: 12, 8: 13, 9: 13}\n",
    "\n",
    "# Create an empty list to store the weights for each row\n",
    "weight_column = []\n",
    "\n",
    "# Iterate over the Fscore values in your DataFrame and assign weights\n",
    "for fscore_value in df['Fscore_momentum']:\n",
    "    weight = weights.get(fscore_value, 9)  # Default weight to 0 if Fscore_momentum is negative\n",
    "    weight_column.append(weight)\n",
    "\n",
    "# Add the weight column to your DataFrame\n",
    "df['Weight'] = weight_column\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "summary_dict = {pivot_row: [], 'Index_Returns': [], 'Low_Fscore_Returns': [], 'Medium_Fscore_Returns': [], 'High_Fscore_Returns': [], 'Momentum_Weighted_High_Fscore_Returns': []}\n",
    "\n",
    "# Calculate and add returns for Fscore categories and by pivot_row\n",
    "for value in df[pivot_row].unique():\n",
    "    value_df = df[df[pivot_row] == value]\n",
    "    \n",
    "    # Equal-weighted returns for the pivot_row\n",
    "    index_returns = equal_weighted_returns(value_df)\n",
    "    \n",
    "    # Equal-weighted returns for Fscore categories\n",
    "    fscore_0_3_returns = equal_weighted_returns(value_df[(value_df['Fscore'] >= 0) & (value_df['Fscore'] <= 3)])\n",
    "    fscore_4_6_returns = equal_weighted_returns(value_df[(value_df['Fscore'] >= 4) & (value_df['Fscore'] <= 6)])\n",
    "    fscore_7_9_returns = equal_weighted_returns(value_df[(value_df['Fscore'] >= 7) & (value_df['Fscore'] <= 9)])\n",
    "    \n",
    "    # Fscore-weighted returns\n",
    "    fscore_7_9_returns_weighted = fscore_weighted_returns(value_df[(value_df['Fscore'] >= 7) & (value_df['Fscore'] <= 9)], 'Weight')\n",
    "    \n",
    "    # Add data to the summary dictionary\n",
    "    summary_dict[pivot_row].append(value)\n",
    "    summary_dict['Index_Returns'].append(index_returns)\n",
    "    summary_dict['Low_Fscore_Returns'].append(fscore_0_3_returns)\n",
    "    summary_dict['Medium_Fscore_Returns'].append(fscore_4_6_returns)\n",
    "    summary_dict['High_Fscore_Returns'].append(fscore_7_9_returns)\n",
    "    summary_dict['Momentum_Weighted_High_Fscore_Returns'].append(fscore_7_9_returns_weighted)\n",
    "    \n",
    "# Calculate overall returns for the entire dataset (without considering region) for each column\n",
    "overall_returns_index = equal_weighted_returns(df)\n",
    "\n",
    "# Weighted returns for all stocks in the dataset (without considering region)\n",
    "overall_returns_low_fscore = equal_weighted_returns(df[(df['Fscore'] >= 0) & (df['Fscore'] <= 3)])\n",
    "overall_returns_medium_fscore = equal_weighted_returns(df[(df['Fscore'] >= 4) & (df['Fscore'] <= 6)])\n",
    "overall_returns_high_fscore = equal_weighted_returns(df[df['Fscore'] >= 7])\n",
    "overall_returns_high_fscore_weighted = fscore_weighted_returns(df[df['Fscore'] >= 7], 'Weight')\n",
    "\n",
    "# Add data to the summary dictionary for overall returns\n",
    "summary_dict[pivot_row].append('Overall')\n",
    "summary_dict['Index_Returns'].append(overall_returns_index)\n",
    "summary_dict['Low_Fscore_Returns'].append(overall_returns_low_fscore)\n",
    "summary_dict['Medium_Fscore_Returns'].append(overall_returns_medium_fscore)\n",
    "summary_dict['High_Fscore_Returns'].append(overall_returns_high_fscore)\n",
    "summary_dict['Momentum_Weighted_High_Fscore_Returns'].append(overall_returns_high_fscore_weighted)\n",
    "\n",
    "# Create a DataFrame from the summary dictionary\n",
    "summary_df2 = pd.DataFrame(summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "256e69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the other metrics for 2023 by Region: accuracy, specificity, sensitivity, and balanced accuracy\n",
    "summary_df2_metrics = calculate_accuracy(df, pivot_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6d817",
   "metadata": {},
   "source": [
    "## 4.2  Compare the results: High-F-score stocks VS Low-F-score stocks VS ADR Stock Index by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7b8c48a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a36c6 caption {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a36c6\">\n",
       "  <caption>Table 3. 2022 Returns Summary by Market Classification</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a36c6_level0_col0\" class=\"col_heading level0 col0\" >Market Classification</th>\n",
       "      <th id=\"T_a36c6_level0_col1\" class=\"col_heading level0 col1\" >Index_Returns</th>\n",
       "      <th id=\"T_a36c6_level0_col2\" class=\"col_heading level0 col2\" >Low_Fscore_Returns</th>\n",
       "      <th id=\"T_a36c6_level0_col3\" class=\"col_heading level0 col3\" >High_Fscore_Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a36c6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a36c6_row0_col0\" class=\"data row0 col0\" >Non-U.S. Developed Markets</td>\n",
       "      <td id=\"T_a36c6_row0_col1\" class=\"data row0 col1\" >-0.174058</td>\n",
       "      <td id=\"T_a36c6_row0_col2\" class=\"data row0 col2\" >-0.286524</td>\n",
       "      <td id=\"T_a36c6_row0_col3\" class=\"data row0 col3\" >-0.143242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a36c6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a36c6_row1_col0\" class=\"data row1 col0\" >Non-U.S. Emerging Markets</td>\n",
       "      <td id=\"T_a36c6_row1_col1\" class=\"data row1 col1\" >-0.086448</td>\n",
       "      <td id=\"T_a36c6_row1_col2\" class=\"data row1 col2\" >-0.218753</td>\n",
       "      <td id=\"T_a36c6_row1_col3\" class=\"data row1 col3\" >-0.073655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a36c6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a36c6_row2_col0\" class=\"data row2 col0\" >Overall</td>\n",
       "      <td id=\"T_a36c6_row2_col1\" class=\"data row2 col1\" >-0.141157</td>\n",
       "      <td id=\"T_a36c6_row2_col2\" class=\"data row2 col2\" >-0.256965</td>\n",
       "      <td id=\"T_a36c6_row2_col3\" class=\"data row2 col3\" >-0.122183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e4d0514b20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 2022 returns summary\n",
    "del summary_df1['Medium_Fscore_Returns'] # delete column, not needed\n",
    "with_title(summary_df1, \"Table 3. 2022 Returns Summary by Market Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb42efd",
   "metadata": {},
   "source": [
    "Based on the results for 2022 in Table 3, the overall performance of high-F-score stocks is better than both the benchmark and the low-F-score stock returns. High-F-score stocks outperform the low-F-score stocks by 13.48% and the benchmark by 1.90%. Low-F-score stocks underperform by 11.58% below the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5eab102",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_927a2 caption {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_927a2\">\n",
       "  <caption>Table 4. 2023 Returns Summary by Market Classification</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_927a2_level0_col0\" class=\"col_heading level0 col0\" >Market Classification</th>\n",
       "      <th id=\"T_927a2_level0_col1\" class=\"col_heading level0 col1\" >Index_Returns</th>\n",
       "      <th id=\"T_927a2_level0_col2\" class=\"col_heading level0 col2\" >Low_Fscore_Returns</th>\n",
       "      <th id=\"T_927a2_level0_col3\" class=\"col_heading level0 col3\" >High_Fscore_Returns</th>\n",
       "      <th id=\"T_927a2_level0_col4\" class=\"col_heading level0 col4\" >Momentum_Weighted_High_Fscore_Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_927a2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_927a2_row0_col0\" class=\"data row0 col0\" >Non-U.S. Developed Markets</td>\n",
       "      <td id=\"T_927a2_row0_col1\" class=\"data row0 col1\" >0.059156</td>\n",
       "      <td id=\"T_927a2_row0_col2\" class=\"data row0 col2\" >-0.013127</td>\n",
       "      <td id=\"T_927a2_row0_col3\" class=\"data row0 col3\" >0.135085</td>\n",
       "      <td id=\"T_927a2_row0_col4\" class=\"data row0 col4\" >0.137368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_927a2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_927a2_row1_col0\" class=\"data row1 col0\" >Non-U.S. Emerging Markets</td>\n",
       "      <td id=\"T_927a2_row1_col1\" class=\"data row1 col1\" >0.074427</td>\n",
       "      <td id=\"T_927a2_row1_col2\" class=\"data row1 col2\" >0.095927</td>\n",
       "      <td id=\"T_927a2_row1_col3\" class=\"data row1 col3\" >0.163673</td>\n",
       "      <td id=\"T_927a2_row1_col4\" class=\"data row1 col4\" >0.157631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_927a2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_927a2_row2_col0\" class=\"data row2 col0\" >Overall</td>\n",
       "      <td id=\"T_927a2_row2_col1\" class=\"data row2 col1\" >0.064891</td>\n",
       "      <td id=\"T_927a2_row2_col2\" class=\"data row2 col2\" >0.031204</td>\n",
       "      <td id=\"T_927a2_row2_col3\" class=\"data row2 col3\" >0.143644</td>\n",
       "      <td id=\"T_927a2_row2_col4\" class=\"data row2 col4\" >0.143490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e4d04f88e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 2023 returns summary\n",
    "del summary_df2['Medium_Fscore_Returns'] # delete column, not needed\n",
    "with_title(summary_df2, \"Table 4. 2023 Returns Summary by Market Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019c794",
   "metadata": {},
   "source": [
    "Results for 2023 in Table 4 show again that high-F-score stocks perform better than both the benchmark and the low-F-score stocks. High-F-score stocks outperform the low-F-score stocks by 11.24% and the benchmark by 7.88%. Low-F-score stocks from Non-U.S. Emerging Markets outperform the benchmark by 2.15% while low-F-score stocks from Non-U.S. Developed Markets underperform by 7.23% below the benchmark. Overall, low-F-score stocks underperform by 3.37% below the benchmark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d53f9f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_672c2 caption {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_672c2\">\n",
       "  <caption>Table 5. 2022 Metrics Summary by Market Classification</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_672c2_level0_col0\" class=\"col_heading level0 col0\" >Market Classification</th>\n",
       "      <th id=\"T_672c2_level0_col1\" class=\"col_heading level0 col1\" >Expected Winner</th>\n",
       "      <th id=\"T_672c2_level0_col2\" class=\"col_heading level0 col2\" >Actual Winner</th>\n",
       "      <th id=\"T_672c2_level0_col3\" class=\"col_heading level0 col3\" >Expected Loser</th>\n",
       "      <th id=\"T_672c2_level0_col4\" class=\"col_heading level0 col4\" >Actual Loser</th>\n",
       "      <th id=\"T_672c2_level0_col5\" class=\"col_heading level0 col5\" >HF Precision</th>\n",
       "      <th id=\"T_672c2_level0_col6\" class=\"col_heading level0 col6\" >LF Precision</th>\n",
       "      <th id=\"T_672c2_level0_col7\" class=\"col_heading level0 col7\" >Overall Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_672c2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_672c2_row0_col0\" class=\"data row0 col0\" >Non-U.S. Developed Markets</td>\n",
       "      <td id=\"T_672c2_row0_col1\" class=\"data row0 col1\" >159</td>\n",
       "      <td id=\"T_672c2_row0_col2\" class=\"data row0 col2\" >85</td>\n",
       "      <td id=\"T_672c2_row0_col3\" class=\"data row0 col3\" >53</td>\n",
       "      <td id=\"T_672c2_row0_col4\" class=\"data row0 col4\" >33</td>\n",
       "      <td id=\"T_672c2_row0_col5\" class=\"data row0 col5\" >0.534591</td>\n",
       "      <td id=\"T_672c2_row0_col6\" class=\"data row0 col6\" >0.622642</td>\n",
       "      <td id=\"T_672c2_row0_col7\" class=\"data row0 col7\" >0.556604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_672c2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_672c2_row1_col0\" class=\"data row1 col0\" >Non-U.S. Emerging Markets</td>\n",
       "      <td id=\"T_672c2_row1_col1\" class=\"data row1 col1\" >69</td>\n",
       "      <td id=\"T_672c2_row1_col2\" class=\"data row1 col2\" >32</td>\n",
       "      <td id=\"T_672c2_row1_col3\" class=\"data row1 col3\" >41</td>\n",
       "      <td id=\"T_672c2_row1_col4\" class=\"data row1 col4\" >25</td>\n",
       "      <td id=\"T_672c2_row1_col5\" class=\"data row1 col5\" >0.463768</td>\n",
       "      <td id=\"T_672c2_row1_col6\" class=\"data row1 col6\" >0.609756</td>\n",
       "      <td id=\"T_672c2_row1_col7\" class=\"data row1 col7\" >0.518182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_672c2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_672c2_row2_col0\" class=\"data row2 col0\" >Overall</td>\n",
       "      <td id=\"T_672c2_row2_col1\" class=\"data row2 col1\" >228</td>\n",
       "      <td id=\"T_672c2_row2_col2\" class=\"data row2 col2\" >117</td>\n",
       "      <td id=\"T_672c2_row2_col3\" class=\"data row2 col3\" >94</td>\n",
       "      <td id=\"T_672c2_row2_col4\" class=\"data row2 col4\" >58</td>\n",
       "      <td id=\"T_672c2_row2_col5\" class=\"data row2 col5\" >0.513158</td>\n",
       "      <td id=\"T_672c2_row2_col6\" class=\"data row2 col6\" >0.617021</td>\n",
       "      <td id=\"T_672c2_row2_col7\" class=\"data row2 col7\" >0.543478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e4d17df220>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 2022 Accuracy Metrics\n",
    "with_title(summary_df1_metrics, \"Table 5. 2022 Metrics Summary by Market Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bc8617f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_040ab caption {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_040ab\">\n",
       "  <caption>Table 6. 2023 Metrics Summary by Market Classification</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_040ab_level0_col0\" class=\"col_heading level0 col0\" >Market Classification</th>\n",
       "      <th id=\"T_040ab_level0_col1\" class=\"col_heading level0 col1\" >Expected Winner</th>\n",
       "      <th id=\"T_040ab_level0_col2\" class=\"col_heading level0 col2\" >Actual Winner</th>\n",
       "      <th id=\"T_040ab_level0_col3\" class=\"col_heading level0 col3\" >Expected Loser</th>\n",
       "      <th id=\"T_040ab_level0_col4\" class=\"col_heading level0 col4\" >Actual Loser</th>\n",
       "      <th id=\"T_040ab_level0_col5\" class=\"col_heading level0 col5\" >HF Precision</th>\n",
       "      <th id=\"T_040ab_level0_col6\" class=\"col_heading level0 col6\" >LF Precision</th>\n",
       "      <th id=\"T_040ab_level0_col7\" class=\"col_heading level0 col7\" >Overall Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_040ab_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_040ab_row0_col0\" class=\"data row0 col0\" >Non-U.S. Developed Markets</td>\n",
       "      <td id=\"T_040ab_row0_col1\" class=\"data row0 col1\" >117</td>\n",
       "      <td id=\"T_040ab_row0_col2\" class=\"data row0 col2\" >63</td>\n",
       "      <td id=\"T_040ab_row0_col3\" class=\"data row0 col3\" >73</td>\n",
       "      <td id=\"T_040ab_row0_col4\" class=\"data row0 col4\" >50</td>\n",
       "      <td id=\"T_040ab_row0_col5\" class=\"data row0 col5\" >0.538462</td>\n",
       "      <td id=\"T_040ab_row0_col6\" class=\"data row0 col6\" >0.684932</td>\n",
       "      <td id=\"T_040ab_row0_col7\" class=\"data row0 col7\" >0.594737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_040ab_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_040ab_row1_col0\" class=\"data row1 col0\" >Non-U.S. Emerging Markets</td>\n",
       "      <td id=\"T_040ab_row1_col1\" class=\"data row1 col1\" >50</td>\n",
       "      <td id=\"T_040ab_row1_col2\" class=\"data row1 col2\" >25</td>\n",
       "      <td id=\"T_040ab_row1_col3\" class=\"data row1 col3\" >50</td>\n",
       "      <td id=\"T_040ab_row1_col4\" class=\"data row1 col4\" >37</td>\n",
       "      <td id=\"T_040ab_row1_col5\" class=\"data row1 col5\" >0.500000</td>\n",
       "      <td id=\"T_040ab_row1_col6\" class=\"data row1 col6\" >0.740000</td>\n",
       "      <td id=\"T_040ab_row1_col7\" class=\"data row1 col7\" >0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_040ab_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_040ab_row2_col0\" class=\"data row2 col0\" >Overall</td>\n",
       "      <td id=\"T_040ab_row2_col1\" class=\"data row2 col1\" >167</td>\n",
       "      <td id=\"T_040ab_row2_col2\" class=\"data row2 col2\" >88</td>\n",
       "      <td id=\"T_040ab_row2_col3\" class=\"data row2 col3\" >123</td>\n",
       "      <td id=\"T_040ab_row2_col4\" class=\"data row2 col4\" >87</td>\n",
       "      <td id=\"T_040ab_row2_col5\" class=\"data row2 col5\" >0.526946</td>\n",
       "      <td id=\"T_040ab_row2_col6\" class=\"data row2 col6\" >0.707317</td>\n",
       "      <td id=\"T_040ab_row2_col7\" class=\"data row2 col7\" >0.603448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e4d17bcf70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the 2023 Accuracy Metrics\n",
    "with_title(summary_df2_metrics, \"Table 6. 2023 Metrics Summary by Market Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1aaf90",
   "metadata": {},
   "source": [
    "Accuracy metrics are presented in Table 5 and Table 6. All precision metrics for 2023 are higher than those of 2022. The most noteworthy is the increase in Low F-score Precision for Non-U.S. Emerging Markets by about 13% in 2023 – from 60.98% in 2022 to 74.00% in 2023. Consequently, the overall Low F-score Precision increased by about 9% in 2023 – from 61.70% in 2022 to 70.73% in 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b159a822",
   "metadata": {},
   "source": [
    "Based on the contrasting performances in benchmark returns as shown in Table 2 and Table 3, 2022 and 2023 can be considered as two periods with different market conditions. 2022 can be considered a period under a ‘bad’ market condition and 2023 a period under a relatively ‘good’ market condition. Disregarding the part of return metrics affected by outliers, the return metrics indicate that the F-score classifier is a better predictor under good market conditions. Precision metrics support this, as shown by the higher precision values in 2023 compared to 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e415458",
   "metadata": {},
   "source": [
    "The return-based results in Table 2 and Table 3 show that high F-score stocks outperform low F-score stocks by about 10%, which is consistent between Non-U.S. Emerging Markets and Non-U.S. Developed Markets. High F-score stocks outperform the benchmark by 1.90% in 2022 and by 7.88% in 2023. High F-score stocks from Non-U.S. Emerging Markets outperform the high F-score stocks from Non-U.S. Developed Markets by 1.80% in 2022. On the other hand, high F-score stocks from Non-U.S. Developed Markets outperform the high F-score stocks Non-U.S. Emerging Markets by 1.33% in 2023. The better performance of high-F-score stocks against the benchmark supports the results from previous studies that Piotroski F-score can be an effective tool in generating Alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca724009",
   "metadata": {},
   "source": [
    "In terms of accuracy, the High F-score Precision is slightly better in Non-U.S. Developing Markets than Non-U.S. Emerging Markets in both years. Between the two market groups, Non-U.S. Developing Markets has higher Low F-score Precision in 2022, but then reverses in 2023. Overall, both returns and precision results are generally uniform between the two market groups especially if both 2022 and 2023 results are considered altogether."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
